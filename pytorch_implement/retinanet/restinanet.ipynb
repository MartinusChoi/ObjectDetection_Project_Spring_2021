{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd033a3111211be4281f3a8c4a9b25563b8d253df502c7e31f5318895c1792a97cb",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Define Dataset\n",
    "\n",
    "dataset : torch.utils.data.Dataset 클래스 상속받아야함.\n",
    "> `__len__`과 `__getitem__` 메서드 구현이 필요\n",
    "\n",
    "- `image` : PIL(Python Image Library) Image size (H, W)\n",
    "- `target` : 다음을 포함하는 dictionary type\n",
    "    - `boxes (FloatTensor[N, 4])`\n",
    "        - N 개의 bounding box의 좌표를 (x0, y0, x1, y1) 형태를 가짐.\n",
    "        - x -> 0 ~ W | y -> 0 ~ H\n",
    "    - `labels (Int64Tensor(N))`\n",
    "        - bounding box 마다의 라벨 정보.\n",
    "        - 0은 항상 배경의 클래스를 표현함.\n",
    "    - `image_id (Int64Tensor(1))`\n",
    "        - image 구분자.\n",
    "        - Dataset의 모든 image 간에 고유한 값이어야함.\n",
    "        - 평가 중에도 사용됨.\n",
    "    - `area (Tesnsor(N))`\n",
    "        - bounding box의 면적\n",
    "        - 면적은 평가 시 작음, 중간, 큰 박스 간의 점수를 내기 위한 기준\n",
    "        - COCO evaluation을 기준으로 함.\n",
    "    - `iscrowd (UInt8Tensor(N))`\n",
    "        - 이 값이 참일 경우 평가에서 제외됨.\n",
    "    - `(Optional) masks (UInt8Tensor(N, H, W))`\n",
    "        - N 개의 객체 마다의 segmentation mask 정보\n",
    "    - `(Optional) keypoints (FloatTensor(N, K, 3))`\n",
    "        - N 개의 객체 마다의 키포인트 정보\n",
    "        - 키포인트는 (x, y, visibility) 형태의 값\n",
    "        - visibility 값이 0인 경우 키포인트는 보이지 않음을 의미\n",
    "        - 데이터 증강(Data augmentation)의 경우 키포인트 좌우 반전의 개념은 데이터 표현에 따라 달라지며, 새로운 키포인트 표현에 대해 “references/detection/transforms.py” 코드 부분을 수정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(object):\n",
    "    def __init__(self, root, transform=None) :\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        # 모든 이미지 파일들을 읽고, 정렬\n",
    "        # 이미지와 label 가져오기\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        self.labels = list(sorted(os.listdir(os.path.join(root, \"labels\"))))\n",
    "\n",
    "    def get(self, idx):\n",
    "        # image와 label들을 읽어옴.\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        label_path = os.path.join(self.root, \"labels\", self.labels[idx])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        label = open(label_path)\n",
    "        labels =[]\n",
    "        while True:\n",
    "            line = label.readline()\n",
    "            \n",
    "            if not line: break\n",
    "            \n",
    "            \n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            labels.append(line)\n",
    "\n",
    "        labels = np.array(labels)\n",
    "        obj_ids = np.unique(labels)\n",
    "\n",
    "        return img, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0.415625 0.867361 0.229687 0.170833\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['0 0.415625 0.867361 0.229687 0.170833\\n'], dtype='<U38')"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "data_root = \"./\"\n",
    "\n",
    "dataset = CustomDataset(data_root)\n",
    "\n",
    "image, target = dataset.get(0)\n",
    "\n",
    "target"
   ]
  }
 ]
}